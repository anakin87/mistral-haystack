# ğŸ“Œ mistral-haystack collection
 **Mistral + Haystack Collection: build RAG pipelines that rock ğŸ¤˜**

 Collection of notebooks and resources to build Retrieval Augmented Generation pipelines using:
 - [Mistral](https://mistral.ai/) models ğŸ¤–
 - [Haystack](https://github.com/deepset-ai/haystack) LLM orchestration framework ğŸ—ï¸.


 <img src="https://static.otta.com/uploads/images/company-logos/17023-r1fn8E7CIWJX0L-iFw8YivXD9C37itYuFvVWW_xFh5k.svg" width="270" style="display:inline;"><img src="https://img.freepik.com/premium-vector/electric-guitar-fire-hot-rock-music-guitar-flames-hard-rock-rock-roll-concert-festival-label-night-club-live-show-vector-logo-emblem_570429-23178.jpg?w=2000" width="180"><img src="https://haystack.deepset.ai/images/haystack-ogimage.png" width="360" style="display:inline;">


## ğŸ““ Notebooks

| **Model**                | **Haystack version** | **Link** | **Details**                                             | **Author** |
|--------------------------|----------------------|----------|---------------------------------------------------------|------------|
| Mistral-7B-Instruct-v0.1 | 1.x                  |  [ğŸ¸ Notebook](mistral_haystack.ipynb) | RAG on a collection of Rock music resources, using the free Hugging Face Inference API | [@anakin87](https://github.com/anakin87)   |
| Mixtral-8x7B-Instruct-v0.1 | 1.x                  |  [ğŸ“„ğŸš€ Notebook](https://colab.research.google.com/drive/1rH8df-C3P9pL4yrC2qSae9IOtx5Mr1N_) | RAG on a PDF File, using the free Hugging Face Inference API | [@AlessandroDiLauro](https://github.com/alessandrodilauro)   |
| Mixtral-8x7B-Instruct-v0.1 | 2.x                  |  [ğŸ•¸ï¸ğŸ’¬ Notebook](https://colab.research.google.com/drive/1gsxurwwWK08ZZcPpzz_8yXlsLNZEDqUz) | RAG on the Web, using the free Hugging Face Inference API | [@TuanaCelik](https://github.com/tuanacelik)   |
| Zephyr-7B Beta | 2.x                  |  [ğŸª Article and notebook](https://haystack.deepset.ai/blog/guide-to-using-zephyr-with-haystack2) | Article on how make  this great model (fine-tuned from Mistral) run locally on Colab | [@TuanaCelik](https://github.com/tuanacelik) [@anakin87](https://github.com/anakin87)   |
